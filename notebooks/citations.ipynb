{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Citations Intrinsic\n",
    "\n",
    "This notebook demonstrates some examples of using the Granite citations intrinsic. It uses the shared IO processing code for intrinsics when performing model inference with an OpenAI-compatible backend such as vLLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports go in this cell\n",
    "import openai\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import granite_common\n",
    "from granite_common import ChatCompletion\n",
    "from granite_common.base.types import AssistantMessage\n",
    "from granite_common.intrinsics.constants import BASE_MODEL_TO_CANONICAL_NAME\n",
    "from granite_common.visualization import CitationsWidget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsic_name = \"citations\"\n",
    "base_model_name = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "\n",
    "# Change the following two constants as needed to reflect the location of the\n",
    "# inference server.\n",
    "openai_base_url = \"http://localhost:55555/v1\"\n",
    "openai_api_key = \"rag_intrinsics_1234\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate IO processing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch IO configuration file from Hugging Face Hub\n",
    "io_yaml_file = granite_common.intrinsics.util.obtain_io_yaml(\n",
    "    intrinsic_name, BASE_MODEL_TO_CANONICAL_NAME[base_model_name]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Instantiating input and output processing from configuration file:\\n\"\n",
    "    f\"{io_yaml_file}\"\n",
    ")\n",
    "\n",
    "intrinsics_rewriter = granite_common.IntrinsicsRewriter(config_file=io_yaml_file)\n",
    "intrinsincs_result_processor = granite_common.IntrinsicsResultProcessor(\n",
    "    config_file=io_yaml_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform input processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example chat completion with a user question and two documents.\n",
    "chat_input = ChatCompletion.model_validate(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the visibility level of Git Repos and Issue \\\n",
    "Tracking projects?\",\n",
    "            }\n",
    "        ],\n",
    "        \"extra_body\": {\n",
    "            \"documents\": [\n",
    "                {\n",
    "                    \"doc_id\": \"1\",\n",
    "                    \"text\": \"Git Repos and Issue Tracking is an IBM-hosted \\\n",
    "component of \\\n",
    "the Continuous Delivery service. All of the data that you provide to Git Repos and \\\n",
    "Issue Tracking, including but not limited to source files, issues, pull requests, and \\\n",
    "project configuration properties, is managed securely within Continuous Delivery. \\\n",
    "However, Git Repos and Issue Tracking supports various mechanisms for exporting, \\\n",
    "sending, or otherwise sharing data to users and third parties. The ability of Git \\\n",
    "Repos and Issue Tracking to share information is typical of many social coding \\\n",
    "platforms. However, such sharing might conflict with regulatory controls that \\\n",
    "apply to your business. After you create a project in Git Repos and Issue Tracking, \\\n",
    "but before you entrust any files, issues, records, or other data with the project, \\\n",
    "review the project settings and change any settings that you deem necessary to \\\n",
    "protect your data. Settings to review include visibility levels, email notifications, \\\n",
    "integrations, web hooks, access tokens, deploy tokens, and deploy keys. Project \\\n",
    "visibility levels \\n\\nGit Repos and Issue Tracking projects can have one of the \\\n",
    "following visibility levels: private, internal, or public. * Private projects are \\\n",
    "visible only to project members. This setting is the default visibility level for new \\\n",
    "projects, and is the most secure visibility level for your data. * Internal projects \\\n",
    "are visible to all users that are logged in to IBM Cloud. * Public projects are \\\n",
    "visible to anyone. To limit project access to only project members, complete the \\\n",
    "following steps:\\n\\n\\n\\n1. From the project sidebar, click Settings > General. \\\n",
    "2. On the General Settings page, click Visibility > project features > permissions. \\\n",
    "3. Locate the Project visibility setting. 4. Select Private, if it is not already \\\n",
    "selected. 5. Click Save changes. Project membership \\n\\nGit Repos and Issue Tracking \\\n",
    "is a cloud hosted social coding environment that is available to all Continuous \\\n",
    "Delivery users. If you are a Git Repos and Issue Tracking project Maintainer or Owner, \\\n",
    "you can invite any user and group members to the project. IBM Cloud places no \\\n",
    "restrictions on who you can invite to a project.\",\n",
    "                },\n",
    "                {\n",
    "                    \"doc_id\": \"2\",\n",
    "                    \"text\": \"After you create a project in Git Repos and Issue \\\n",
    "Tracking, but before you entrust any files, issues, records, or other data with \\\n",
    "the project, review the project settings and change any settings that are \\\n",
    "necessary to protect your data. \\\n",
    "Settings to review include visibility levels, email notifications, integrations, web \\\n",
    "hooks, access tokens, deploy tokens, and deploy keys. Project visibility levels \\\n",
    "\\n\\nGit Repos and Issue Tracking projects can have one of the following visibility \\\n",
    "levels: private, internal, or public. * Private projects are visible only to \\\n",
    "project members. This setting is the default visibility level for new projects, and \\\n",
    "is the most secure visibility level for your data. * Internal projects are visible to \\\n",
    "all users that are logged in to IBM Cloud. * Public projects are visible to anyone. \\\n",
    "To limit project access to only project members, complete the following \\\n",
    "steps:\\n\\n\\n\\n1. From the project sidebar, click Settings > General. 2. On the \\\n",
    "General Settings page, click Visibility > project features > permissions. 3. Locate \\\n",
    "the Project visibility setting. 4. Select Private, if it is not already selected. \\\n",
    "5. Click Save changes. Project email settings \\n\\nBy default, Git Repos and Issue \\\n",
    "Tracking notifies project members by way of email about project activities. These \\\n",
    "emails typically include customer-owned data that was provided to Git Repos and Issue \\\n",
    "Tracking by users. For example, if a user posts a comment to an issue, Git Repos and \\\n",
    "Issue Tracking sends an email to all subscribers. The email includes information such \\\n",
    "as a copy of the comment, the user who posted it, and when the comment was posted. \\\n",
    "To turn off all email notifications for your project, complete the following \\\n",
    "steps:\\n\\n\\n\\n1. From the project sidebar, click Settings > General. 2. On the \\\n",
    "**General Settings **page, click Visibility > project features > permissions. \\\n",
    "3. Select the Disable email notifications checkbox. 4. Click Save changes. Project \\\n",
    "integrations and webhooks\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"model\": base_model_name,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    ")\n",
    "print(chat_input.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the inference server\n",
    "client = openai.OpenAI(base_url=openai_base_url, api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the example through Granite to get an answer\n",
    "chat_input.model = base_model_name\n",
    "chat_completion = client.chat.completions.create(**chat_input.model_dump())\n",
    "\n",
    "chat_completion_message = chat_completion.choices[0].message\n",
    "\n",
    "display(Markdown(chat_completion_message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_chat_input = chat_input.model_copy(deep=True)\n",
    "next_chat_input.messages.append(chat_completion_message)\n",
    "next_chat_input.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run request through intrinsics input processing\n",
    "intrinsics_input = next_chat_input.model_copy(deep=True)\n",
    "intrinsics_input.model = intrinsic_name\n",
    "\n",
    "intrinsics_request = intrinsics_rewriter.transform(intrinsics_input)\n",
    "print(intrinsics_request.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw intrinsics output\n",
    "intrinsics_completion = client.chat.completions.create(\n",
    "    **intrinsics_request.model_dump()\n",
    ")\n",
    "intrinsics_completion_message = intrinsics_completion.choices[0].message\n",
    "\n",
    "print(intrinsics_completion_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_chat_completion = intrinsincs_result_processor.transform(\n",
    "    intrinsics_completion, intrinsics_request\n",
    ")\n",
    "\n",
    "print(processed_chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize citations using citations widget\n",
    "CitationsWidget().show(intrinsics_input, intrinsics_completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poor-quality assistant response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with an artifical poor-quality assistant response.\n",
    "alt_chat_input = chat_input.model_copy(deep=True)\n",
    "alt_chat_input.messages.append(\n",
    "    AssistantMessage(\n",
    "        content=\"Git repos are generally only visible in the infrared \"\n",
    "        \"spectrum, due to their natural camouflage. Issue Tracking projects \"\n",
    "        \"are much easier to see; their bright colors warn predators of the \"\n",
    "        \"poisonous technical debt that they secrete.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "alt_intrinsics_input = alt_chat_input.model_copy(deep=True)\n",
    "alt_intrinsics_input.model = intrinsic_name\n",
    "alt_intrinsics_request = intrinsics_rewriter.transform(alt_intrinsics_input)\n",
    "\n",
    "alt_intrinsics_completion = client.chat.completions.create(\n",
    "    **alt_intrinsics_request.model_dump()\n",
    ")\n",
    "alt_intrinsics_completion_message = alt_intrinsics_completion.choices[0].message\n",
    "\n",
    "processed_chat_completion = intrinsincs_result_processor.transform(\n",
    "    alt_intrinsics_completion, alt_intrinsics_request\n",
    ")\n",
    "\n",
    "print(processed_chat_completion.choices[0].model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "chat_input_5 = chat_input.model_copy(deep=True)\n",
    "chat_input_5.n = 5\n",
    "chat_input_5.temperature = 0.7\n",
    "chat_input_5.model = base_model_name\n",
    "chat_completion_5 = client.chat.completions.create(**chat_input_5.model_dump())\n",
    "\n",
    "for choice in chat_completion_5.choices:\n",
    "    choice_chat_input = chat_input.model_copy(deep=True)\n",
    "    choice_chat_input.model = intrinsic_name\n",
    "    choice_chat_input.n = 1\n",
    "    choice_chat_input.temperature = 0.0\n",
    "\n",
    "    intrinsics_request = intrinsics_rewriter.transform(choice_chat_input)\n",
    "    intrinsics_completion = client.chat.completions.create(\n",
    "        **intrinsics_request.model_dump()\n",
    "    )\n",
    "    # print(intrinsics_request.model_dump_json(indent=2))\n",
    "    # print(intrinsics_completion.model_dump_json(indent=2))\n",
    "\n",
    "    processed_chat_completion = intrinsincs_result_processor.transform(\n",
    "        intrinsics_completion, intrinsics_request\n",
    "    )\n",
    "\n",
    "    citations = json.loads(processed_chat_completion.choices[0].message.content)\n",
    "\n",
    "    print(f\"Assistant: {choice.message.content}\")\n",
    "    print(f\"           ({len(citations)} citations)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "granite-common",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
